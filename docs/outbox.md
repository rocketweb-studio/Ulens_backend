Перед запуском проекта поднять в докере Rabbit, Redis, Kafka. docker compose файлы смотреть в либах.
Топики для Kafka создаем через команду в терминал, после того как поднялся контейнер с Kafka.
При ежедневном запуске Kafka в dev режиме:
1.docker compose up -d
2.Создаем топики:  docker compose exec redpanda rpk topic create app.events.v1 -p 3 -r 1 || true
	-docker compose exec redpanda ... — выполнить команду внутри контейнера 
	- rpk topic create <name> — создать топик.
	-p 3 — 3 партиции (параллелизм/масштабирование по ключу).
	-r 1 — фактор репликации 1 (для локального одиночного узла).
	|| true — если топик уже есть и rpk вернёт ошибку, игнорируем (команда не 		«завалит» скрипт). То есть команда становится идемпотентной.
3.Создать топик demo.keys.v1 (аналогично):
	docker compose exec redpanda rpk topic create demo.keys.v1 -p 3 -r 1 || true
4.Проверить конфигурацию топика: docker compose exec redpanda rpk topic describe app.events.v1
	Покажет детали: число партиций, лидеров по каждой партиции, конфиги (retention и т. д.).
5.Посмотреть список всех топиков: docker compose exec redpanda rpk topic list
ЕСЛИ был примонтирован volume,то топики создаем только один раз при первоначалльном запуске


Примерный флоу outbox на момент начальной реализации (пока без платежной системы):
Эндпоинт subscriptions(Gateway -> Payments)
1.SubscriptionService (payments srv, добавляем запись в Redis) 
2.SubscriptionCommandRepo (payments srv) 
3.OutboxPublisherKafkaService (payments srv) 
4.AuthKafkaConsumer (auth srv) 
5.UserCommandRepository (auth srv) 
6.AuthKafkaPublisher (auth srv) 
7.PaymentsKafkaConsumer (payments srv) 
8.SubscriptionCommandRepo (payments srv)

Указаны названия классов с логикой связанной с оплатой подписки.
Нумерация соответствует фактическому флоу. В качестве consumer и publisher указана Kafka.
Также все может работать и с Rabbit. Для публикации сообщений они используют общий интерфейс EventBus.
Для переключения с одного брокера на другой при помощи поиска находим места  switchMessageBroker** .
Cейчас в качестве Idempatency-Key задаем заголовок в postman и используем там UUID значение.
Позже это значение будет генерироваться и храниться фронте. Уникальное значение этого заголовка
	гарантирует, что это новая транзакция, а не n-ая попытка повторить завершенную или ту которая 
	обрабатывается в данный момент. 
При тестировании из postman важно помнить что Idempatency-Key храниться в Redis. И во время отладки нужно
	либо чистить её руками (RedisInsight), либо отправлять заголовок с новым значение Idempatency-Key.

В файл package.json в команды запуска микросервисов payments и auth задаем переменную SERVICE.
Она используется в kafka.module.ts чтобы задать нужные GROUP_ID для каждого микросервиса, иначе они будут
	консьюмить свои же сообщения.


fromBeginning: true в Kafka consumers:

Не обязательно, но это хорошая практика для безопасности (особенно в dev).
Если оставить false — консьюмер должен быть запущен до генерации событий, иначе они будут пропущены.
Если поставить true — консьюмер для новой группы прочитает все сообщения с начала и ничего не потеряет. 
	Дубли при этом безопасны, так как обрабатываются через Inbox/идемпотентность (настроено у нас).
Что делает fromBeginning
В Kafka сообщения не хранятся в очереди (как в RabbitMQ), а записываются в лог (топик). Группа хранит свой offset.
fromBeginning: true — если у группы нет оффсета, чтение начинается с самого раннего сообщения (earliest).
Если оффсет есть, флаг игнорируется, продолжается чтение с сохранённого места.
fromBeginning: false — если оффсета нет, чтение начнётся с конца (latest), все старые сообщения будут пропущены.
Разница с RabbitMQ
RabbitMQ: сообщение хранится в очереди и будет доставлено любому подключившемуся потребителю.
Kafka: сообщение хранится в топике, а кто его прочитает зависит от группы и её оффсета. Новый консьюмер с latest пропустит все старые события.
Рекомендации:
Использовать разные groupId для разных сервисов (у нас auth-events, payments-events).
В dev окружении рекомендуется оставлять fromBeginning: true, чтобы не зависеть от порядка запуска и не терять события.
В продакшене допустимо false, так как группы уже имеют сохранённые оффсеты.
Если событие было пропущено:
сбросить оффсеты группы (rpk group delete payments-events или seek на start),
либо сгенерировать новое событие.
Не завязываться на порядок запуска сервисов — при fromBeginning: true новые группы всё равно прочитают историю.
Следить за логом группы в Kafka UI или через rpk group describe ….
Использовать ключи сообщений (например, userId) для гарантированного порядка обработки внутри одной партиции.

Остальное смотреть двигаясь по коду файлов перечисленных в списке (Примерный флоу...). Старался оставлять
	большое количество комментариев